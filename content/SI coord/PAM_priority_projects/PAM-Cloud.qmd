---
title: NMFS PAM Operational Cloud Storage and Processing
---

![](/content/images/Priority_project_graphics/Cloud/Direct-upload-cloud.png){width=25%}

### Team Leads 
Sofie Van Parijs (NEFSC), Dan Woodrich (AFSC)

### Goal 
Demonstrate a scalable and cost-effective cloud-based workflow to modernize NMFS PAM operations and support the protected species mission\

### Target outcome
Developing a National PAM Cloud operational repository for data processing and storage

![](/content/images/Priority_project_graphics/Cloud/flowchart.PNG)

### Project Resources

<details>
<summary><font size = "5">PAM GCP Technical System Documentation</font></summary>

#### Overview 
Summary of key decisions, technical system set-up, and use expectations for using software applications in the PAM GCP. This document is an initial way to collaborate on developing the documentation and will be transitioned to the National PAM Network GitHub once folks have access. 

#### The acoustics SI and project design philosophy:
The ggn-nmfs-pamdata-prod-1 (“pamdata”) GCP project is designed to encompass the requirements of the PAM SI, while best prioritizing the wants and needs of the end-users and use cases, and staying near best admin practices for NMFS OCIO GCP. The relevant objectives of the PAM acoustics SI include acoustic data storage across NMFS, and passive acoustic monitoring applications that generally feed from this data. The primary end-users of the system include data owners and users, and application owners, developers, and users. 

#### Permissions structure: 
A principle and role based structure was designed for project capabilities. By defining specific [principle groups](https://source.cloud.google.com/ggn-nmfs-pamdata-prod-1/tf-repo-pamdata/+/master:principles.tf) (project supervisor, application developer, etc) the project is resilient to changes in individual users. [Roles](https://source.cloud.google.com/ggn-nmfs-pamdata-prod-1/tf-repo-pamdata/+/master:roles.tf) are given to these principle groups- for example, the project supervisors principle group is given viewing roles for most of the resources in the project for their visibility.  

For quick configuration and transparency during the dynamic early stages of the project, principle and role definitions are managed by a central “project admin” principle group via terraform. NMFS OCIO best practice recommends [Terraform](https://docs.google.com/document/d/1SPbbIz2hN4Gh236C7uAwGjzk-2AnpTPECJLsHB1RMPM/edit#heading=h.urcjjnawq27j) for more transparent project resource configuration and management, and this allows for simplicity and transparency. 

Alternatives: In the future, we may wish to delegate assignment of users to principle groups in a way that better resembles the true acoustics SI responsible parties (ie, supervisors can assign the project admin(s), data authorities can designate their respective data admin(s), etc). In the short term, this may result in too much unpredictability to the dynamic project. 

Below are some of the currently defined principles for the project: 

| Principle group name | Definition and roles |
| :---- | :---- |
| Project admin | Highest GCP admin role, controls project terraform (all principle, role, resource definitions) |
| Project supervisors | Highest SI role, has visibility across project resources, tells project admin what to do |
| Data authority | Responsible party for a particular FMC data storage bucket |
| Data admin | Administrates the contents (write/delete) of a particular storage bucket |
| Application developer | Access to software development resources |

#### Resources:

The pamdata project is expected to house PAM data from across NMFS, application development resources, and various applications (\<30) in various states of development. Sprawl is a serious threat, in particular since many end-users of the system (owners/authorities, supervisors, users) tend to understand the system through use of a web browser as opposed to filterable api calls. In other words, resource sprawl will lead to reduced understandability of the project across the PAM SI end users and is thus carefully considered. 

#### Data resources:

Each FMC has a distinct storage bucket for their data. This allows for some flexibility in data naming and easier isolation of permissions between FMCs. Principle groups that are designated here are data authorities (the data owner or responsible party, usually the PI of an FMC acoustics group), and the data admins (the technical users responsible for maintaining the contents of the storage bucket).

The browser allows for [easy viewing of the storage buckets](https://console.cloud.google.com/storage/browser?project=ggn-nmfs-pamdata-prod-1) such that non-technical users can easily interpret the current state of the data across the NMFS FMCs. However, the tool cannot distinguish the FMC buckets from application buckets, and in order to maintain easy interpretability applications will be encouraged to consolidate to fewer buckets as appropriate. Currently, three additional buckets outside of the FMC data buckets exist: the terraform state bucket, an application intermediate bucket, and an application output bucket.  

#### Development resources

The following resources have been stood up for application development: 

**Hardened docker image/server:** \
Based on NMFS hardened linux container and preloaded with docker. I developed an imagining pipeline for this, meaning it will be easy to keep up to date and we can make as many copies of this as developers need them. Developing on this instead of locally will be a little closer to cloud and streamlines and simplifies some assumptions. Please make sure any developers working on containers understand this option exists and the advantages in doing development here (hardware flexibility, more similar to production, built in permissions w/o key management, etc). 

**Docker registry:** \
This is where container images will be placed (whether we build or import them), and it is a key backbone of a variety of GCP container orchestration services. 

**Application storage buckets:** \
There are two new storage buckets, pamdata-app-intermediates and pamdata-app-outputs. Some of the time applications will need their own specific tiering and lifecycle, but I wanted to start with just these two, especially for early development, given that they are visible along with the FMC data buckets and we tend to like to use the console as a browsing tool to keep track of these. Keeping it to two, and dividing permissions by prefix, will keep the bucket display from getting too muddied. 

**Networking:** \
Created networks and subnets \- one for application and development machines, which require ssh and NAT internet connectivity, and one for batch processing, which relies on only private google connectivity by default, but other connectivity can be added as a particular app might need. 
</details>
<details>
<summary><font size = "5">Direct Acoustic Data Upload to Cloud</font></summary>
\
*Result:*

ASFC was able to upload 100TB of acoustic data to our GCP bucket over the internet connection in our science center (in Seattle) in a three week upload window with low operator effort, representing our whole primary acoustic data collection.\

*How:* 

Our research group committed two computers with normal user permissions in the AFSC data center to upload data from the AFSC LAN to our pamdata bucket. These two computers ran a simple script, which was written in R and wrapped calls to the GCP ‘gsutil’ tool. The script was very simple, about 50 lines. The script instructed the computers to only initiate uploads between the hours of 7pm and 6am on weekdays and constantly on weekends. The R sessions were logged so we could identify any early termination that might have resulted in partial or corrupted uploads. Additional process will be designed to check that the data was uploaded in full.\

*Impact:*

AFSC IT would have been notified by the NMFS network team if the traffic were considered disruptive. They would have traced the traffic to the machines under my user name, and contacted me to ask questions. This not happening suggests that the traffic was a non-issue. Scheduling traffic within off-hours (nights and weekends) prevents throttling normal user traffic during working hours, and staying within these confines is respectful and normal practice for NMFS IT groups. We did not notify AFSC IT or the NMFS network team as we wanted to test the impact of this traffic empirically, but going forward, especially with multiple FMCs performing uploads concurrently, we advise approving the traffic with FMC & NMFS IT.\

*Contact:*

Dan Woodrich [daniel.woodrich\@noaa.gov](mailto:daniel.woodrich@noaa.gov) if you would like to explore a similar process for your FMC acoustic data.\
R script: 

```{r, eval=FALSE}
is_weekday = function(x){
  weekdays = c('Thursday','Friday','Monday','Tuesday','Wednesday')
  return(weekdays(x) %in% weekdays)
}

is_after_hours= function(x){
  return(as.integer(format(x,"%H")) < 6 | as.integer(format(x,"%H")) > 18)
}

#cloud data upload. This assumes you are uploading bottom_mounted data , and just uploads the full content of each folder below the 'moorings' folder. Adapt the logic to your needs but note renaming / reorganizing is more complex. 

my_fmc_bucket_name = 'afsc-1'
my_top_level_data_path = "//161.55.120.117/NMML_AcousticsData/Audio_Data/Waves"
moorings = dir(my_top_level_data_path) #gets each subfolder of top level data path. 

#log the job
sink(paste("//akc0ss-n086/NMML_CAEP_Acoustics/Detector/pam_si/upload_log_",Sys.info()['nodename'],".csv",sep=""), append=TRUE, split=TRUE)

work = list(1:200,201:length(moorings)) #in my case we had 435 moorings. 
names(work) = c("computer1-name","computer2-name") #needs to match Sys.info()['nodename'] for computers you are using
moorings = moorings[work[[Sys.info()['nodename']]]]

for(mooring in moorings){
  
  #detect if it's a weekday during work hours, don't start a job. 
  while(is_weekday(Sys.time()) & !is_after_hours(Sys.time())){
    cat(paste('waiting...',Sys.time(),"\n"))
    Sys.sleep(600) #wait 10 minutes until trying again. 
  }
  
  #gsutil needs to be installed on the system through Google Cloud SDK. If you can open up a command line and run 'gsutil help' and recieve a response, the below line will work.  
  string = paste("gsutil -m cp -r ",my_top_level_data_path,mooring," gs://",my_fmc_bucket_name,"/bottom_mounted/",mooring,sep="")
  cat(paste("started",mooring,"at",Sys.time(),"\n"))
  system(string,intern=TRUE) 
  cat(paste("ended",mooring,"at",Sys.time(),"\n"))
}
```
</details>
<details>
<summary><font size = "5">Google Transfer Appliance Set Up Checklist</font></summary>

![](/content/images/Priority_project_graphics/Cloud/google-transfer.png)

1. Enable APIs - this has been completed that the console/project level and the checklist item can simply be marked as complete. 
2. Authorize Service Acounts: Email Dan Woodrich [daniel.woodrich\@noaa.gov](mailto:daniel.woodrich@noaa.gov) the link to the checklist so he can complete that step on your behalf
</details>
<details>
<summary><font size = "5">PAMDATA Windows Workstation User Guide</font></summary>
\

##### **Provision**

Ask Sofie/Becca/Dan for an instance.


##### **Configure gcloud**

All steps in this section only needs to be done once for each computer you want to access the pam-ww from.  

1. To connect to a remote workstation, you have to install software on your primary physical computer. The next steps in this section assume you’re using Windows, alternatives exist for Mac and Linux. 

2. Make sure you have [Google Cloud SDK](https://cloud.google.com/sdk/docs/install-sdk) installed on your primary physical computer. In the section titled “Installing the latest gcloud CLI version”, select your personal computer operating system and follow the steps to configure the client software.

![](/content/images/Priority_project_graphics/Cloud/PAMDATA_Workstation_1.png)

3. Open the terminal (Command Prompt on windows, can use other shells on other OS as long as it works with gcloud) and enter “gcloud auth login”. This will take you to a browser to login with your email password or two-step verification to configure your user credential with gcloud. 

4. The authentication will be successful if you can type in a command line ‘gcloud auth list’ and it returns your NOAA email address. 
    * If asked to pick a cloud project, enter the number associated with ggn-nmfs-pamdata-prod-1

5. Open the VM instances list here to identify the name of your personal windows workstation. The default naming convention is “firstname-lastname-pam-ww”. 

##### **Connect**
Prior to connecting, ensure that the workstation is in an ‘on’ state. You can navigate to the link [here](https://console.cloud.google.com/compute/instances?cloudshell=true&project=ggn-nmfs-pamdata-prod-1) to see the workstation state and turn it on/off in the browser. 

![Green checkmarks means on, circle means state is changing (turning on or off), gray means stopped. The three dots on the right are called the ‘hamburger’ menu where you can turn change the on/off state. ](/content/images/Priority_project_graphics/Cloud/PAMDATA_Workstation_2.png)

Find the instance containing your name, click on the hamburger menu on the right of the row representing that instance, and select ‘on’. This is also how you turn it off.

::: callout-note
Please keep the instance off when not in use, for instance at the end of your workday if you are actively using it. Leaving it on for long periods unnecessarily incurs unneeded cost.
:::

###### **Remote Desktop Connection**

Built-in windows RDP client, usually preinstalled

1. Open up the Windows Command Prompt if on windows. 
2. Enter the below line of code into the command line to log in as a user. The pattern is [firstname]-[lastname]-pam-ww. It will match the name of the workstation, which you can reference in the link to the pam-ww management [page](https://console.cloud.google.com/compute/instances?cloudshell=true&project=ggn-nmfs-pamdata-prod-1). For example, for user “rebecca.vanhoeck@noaa.gov”, you would enter in cmd:

```{r, eval=F}
start gcloud compute start-iap-tunnel rebecca-vanhoeck-pam-ww 3389 --local-host-port=localhost:3390 --zone=us-east4-c --project=ggn-nmfs-pamdata-prod-1 && timeout 5 && mstsc /v:localhost:3390
```
Change the above code to match your username. 

Enter the code. When prompted, enter pam_user for user, do not supply a password, and hit enter. Accept any warnings that look reasonable. Remote desktop connection will supply the correct username on subsequent logins

::: callout-note
Some users report issues associated with connecting with the above command. If you have similar issues, try running in cmd with: 

*gcloud compute start-iap-tunnel rebecca-vanhoeck-pam-ww 3389 --local-host-port=localhost:3390 --zone=us-east4-c --project=ggn-nmfs-pamdata-prod-1*

Like above, change the above code to match your username. Then, leaving the terminal window running, navigate to “remote desktop connection” application, and enter in localhost:3390. Like with above, supply the username as pam_user and no password. 

For even quicker logins, you can copy the code into a text file, rename to make it have a .bat extension instead of .txt extension (if your primary physical computer is Windows), and then double click it. The code will run in the cmd line when you double click it, so you don’t have to open cmd prompt and copy paste the code in each time.
:::

##### **Upgrade**
The pam-ww template image is upgraded in a versioned manner to fix bugs and add new features and software. Currently the default support model is just to replace pam-ww when upgrades are needed. Be aware that upgrading will wipe out your local files on the instance as well as any customized software you or admins have installed on your particular instance.If you’d like a newer build of the pam-ww, request an upgrade from [daniel.woodrich@noaa.gov](mailto:daniel.woodrich@noaa.gov). You can, and it is in fact preferred, to delete your own pam-ww in advance prior to requesting an upgrade to the latest version. 

If there are specific software you’d like installed on your workstation, ask [daniel.woodrich@noaa.gov](mailto:daniel.woodrich@noaa.gov) to remote into your instance and install the software on your behalf. In some cases software needs admin privileges as well as personal license credentials with the service (such as MATLAB), in these cases we will set up a shared session to install together. 

Sometimes it is not clear if you need an update, since you may be unsure which version you are on and what features or changes have been made in successive versions. The next steps are to check your current image and determine which features have been added which can help you decide if you’d like an update. 

##### **Check your current image**
You can see the current version of your pam-ww by going to the [homepage](https://console.cloud.google.com/compute/instances?project=ggn-nmfs-pamdata-prod-1), clicking on the name of your pam-ww (with the name of your pam-ww)

![](/content/images/Priority_project_graphics/Cloud/PAMDATA_Workstation_3.png)

The text under the ‘image’ field indicates the current version of your pam-ww. The pam-ww image name is between the text “pww-disa” and “hardened…”, in this case, “beta-3”. You can cross reference this with the following documents that track the changes. Both are organized in consecutive order where the last entry represents the most recent available version. 

* [PAM-ww template change tracking](https://docs.google.com/spreadsheets/d/1uYMeBy8f8OI4st7ZWvpnbl9-DPmnF-ZgWeGDjNhqDUE/edit?usp=sharing)
* [PAM-ww versioned build steps](https://docs.google.com/document/d/1SFP5HuQox5JcSEmV2D_M7O_llcFEE_jUEOmpxTr19nY/edit?usp=sharing)

::: callout-note
We are currently working on github based process to formalize provisioning and updating processes and hope to make this aspect of the pam-ww increasingly streamlined. 
:::

</details>

### Report bug/issue in PAM windows workstation
* [Report a bug](https://app.smartsheetgov.com/b/form/cb361c4cdbd7416c90bb5905020174a6)
* [Bug Tracking](https://app.smartsheetgov.com/b/home?dlp=%2Fsheets%2FcQ7v4XMHJVWMPf938jpgCF46695VP7Fc8J2p6HH1&dlq=view%3Dcard%26cardLevel%3D0%26cardViewByColumnId%3D5253881597847428)
