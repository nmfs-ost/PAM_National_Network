[
  {
    "objectID": "content/Onboarding.html",
    "href": "content/Onboarding.html",
    "title": "Onboarding",
    "section": "",
    "text": "This page is optional but can be used as a landing page for new lab members. You can include introductory information, links to must read papers, new hire resources, goal setting information, etc.\nFaylab example",
    "crumbs": [
      "Optional Pages",
      "Onboarding"
    ]
  },
  {
    "objectID": "content/Safety.html",
    "href": "content/Safety.html",
    "title": "Safety",
    "section": "",
    "text": "Include the following information on this page\n\nLab safety\nField safety\nLink to your centers safety website\nIncident reporting directions\nChemical inventory (if applicable)\nLithium battery safety\n\nThis is an essential section to include if your lab uses these. Work with your lab safety manager to develop handling and storage instructions. See SAEL lab manual lithium battery page\n\nSAEL Lab Example & Glider Lab Manual"
  },
  {
    "objectID": "content/Hardware.html",
    "href": "content/Hardware.html",
    "title": "Hardware",
    "section": "",
    "text": "A hardware section is required and should include the following information;\n\nInformation on your recorders\nArray configurations and diagrams\nPlatform information (towed, moored, drifting, etc.)\nOther sensors included (GPS devices, depth senors, etc.)\n\nThis will be variable for each center and may change from project to project. You should list all hardware, present and past.\nYou can also link to a separate hardware repository if needed (SAEL example).\nThis can be a section with subpages or a qmd",
    "crumbs": [
      "Hardware"
    ]
  },
  {
    "objectID": "content/Resources.html",
    "href": "content/Resources.html",
    "title": "Resources",
    "section": "",
    "text": "This page is optional but can be a good spot for any remaining resources or tools you want easy access to.",
    "crumbs": [
      "Optional Pages",
      "Resources"
    ]
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/acknowledgements.html",
    "href": "content/NMFS_OpenSciDirections/acknowledgements.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "This repo and GitHub Action was based on the tutorial by Openscapes quarto-website-tutorial by Julia Lowndes and Stefanie Butland."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/rmarkdown.html",
    "href": "content/NMFS_OpenSciDirections/rmarkdown.html",
    "title": "R Markdown",
    "section": "",
    "text": "You can include R Markdown files in your project."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/rmarkdown.html#r-markdown",
    "href": "content/NMFS_OpenSciDirections/rmarkdown.html#r-markdown",
    "title": "R Markdown",
    "section": "R Markdown",
    "text": "R Markdown\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00"
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/rmarkdown.html#including-plots",
    "href": "content/NMFS_OpenSciDirections/rmarkdown.html#including-plots",
    "title": "R Markdown",
    "section": "Including Plots",
    "text": "Including Plots\nYou can also embed plots, for example:\n\n\n\n\n\n\n\n\n\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/rendering.html",
    "href": "content/NMFS_OpenSciDirections/rendering.html",
    "title": "Rendering",
    "section": "",
    "text": "The repo includes a GitHub Action that will render (build) the website automatically when you make changes to the files. It will be pushed to the gh-pages branch.\nBut when you are developing your content, you will want to render it locally."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/rendering.html#step-1.-make-sure-you-have-a-recent-rstudio",
    "href": "content/NMFS_OpenSciDirections/rendering.html#step-1.-make-sure-you-have-a-recent-rstudio",
    "title": "Rendering",
    "section": "Step 1. Make sure you have a recent RStudio",
    "text": "Step 1. Make sure you have a recent RStudio\nHave you updated RStudio since about August 2022? No? Then update to a newer version of RStudio. In general, you want to keep RStudio updated and it is required to have a recent version to use Quarto."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/rendering.html#step-2.-clone-and-create-rstudio-project",
    "href": "content/NMFS_OpenSciDirections/rendering.html#step-2.-clone-and-create-rstudio-project",
    "title": "Rendering",
    "section": "Step 2. Clone and create RStudio project",
    "text": "Step 2. Clone and create RStudio project\nFirst, clone the repo onto your local computer. How? You can click File &gt; New Project and then select “Version Control”. Paste in the url of the repository. That will clone the repo on to your local computer. When you make changes, you will need to push those up."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/rendering.html#step-3.-render-within-rstudio",
    "href": "content/NMFS_OpenSciDirections/rendering.html#step-3.-render-within-rstudio",
    "title": "Rendering",
    "section": "Step 3. Render within RStudio",
    "text": "Step 3. Render within RStudio\nRStudio will recognize that this is a Quarto project by the presence of the _quarto.yml file and will see the “Build” tab. Click the “Render website” button to render to the _site folder.\nPreviewing: You can either click index.html in the _site folder and specify “preview in browser” or set up RStudio to preview to the viewer panel. To do the latter, go to Tools &gt; Global Options &gt; R Markdown. Then select “Show output preview in: Viewer panel”."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/publishing.html",
    "href": "content/NMFS_OpenSciDirections/publishing.html",
    "title": "Publishing",
    "section": "",
    "text": "To get your Quarto webpage to show up with the url\nyou have a few steps."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/publishing.html#turn-on-github-pages-for-your-repo",
    "href": "content/NMFS_OpenSciDirections/publishing.html#turn-on-github-pages-for-your-repo",
    "title": "Publishing",
    "section": "Turn on GitHub Pages for your repo",
    "text": "Turn on GitHub Pages for your repo\n\nTurn on GitHub Pages under Settings &gt; Pages . You will set pages to be made from the gh-pages branch and the root directory.\nTurn on GitHub Actions under Settings &gt; Actions &gt; General\n\nThe GitHub Action will automatically recreate your website when you push to GitHub after you do the initial gh-pages set-up"
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/publishing.html#do-your-first-publish-to-gh-pages",
    "href": "content/NMFS_OpenSciDirections/publishing.html#do-your-first-publish-to-gh-pages",
    "title": "Publishing",
    "section": "Do your first publish to gh-pages",
    "text": "Do your first publish to gh-pages\nThe first time you publish to gh-pages, you need to do so locally.\n\nOn your local computer, open a terminal window and cd to your repo directory. Here is what that cd command looks like for me. You command will look different because your local repo will be somewhere else on your computer.\n\ncd ~/Documents/GitHub/NOAA-quarto-simple\n\nPublish to the gh-pages. In the terminal type\n\nquarto publish gh-pages\nThis is going to render your webpage and then push the _site contents to the gh-pages branch."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/publishing.html#dont-like-using-gh-pages",
    "href": "content/NMFS_OpenSciDirections/publishing.html#dont-like-using-gh-pages",
    "title": "Publishing",
    "section": "Don’t like using gh-pages?",
    "text": "Don’t like using gh-pages?\nIn some cases, you don’t want your website on the gh-pages branch. For example, if you are creating releases and you want the website pages archived in that release, then you won’t want your website pages on the gh-pages branch.\nHere are the changes you need to make if you to avoid gh-pages branch.\n\nAt the top of _quarto.yml add the following:\n\nproject: \n  type: website\n  output-dir: docs\n\nOn GitHub under Settings &gt; Pages set pages to be made from the main branch and the docs directory.\nMake sure docs is not listed in .gitignore\nPublish the site the first time locally using quarto publish from the terminal\nChange the GitHub Action because you can’t use quarto publish gh-pages. You’ll need to push to the main branch yourself (in the GitHub Action)\n\non:\n  push:\n    branches: main\n\nname: Render and Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v2 \n        \n      - name: Set up R (needed for Rmd)\n        uses: r-lib/actions/setup-r@v2\n\n      - name: Install packages (needed for Rmd)\n        run: Rscript -e 'install.packages(c(\"rmarkdown\", \"knitr\", \"jsonlite\"))'\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n        with:\n          # To install LaTeX to build PDF book \n          # tinytex: true \n          # uncomment below and fill to pin a version\n          # version: 0.9.600\n      \n      - name: Render Quarto Project\n        uses: quarto-dev/quarto-actions/render@v2\n        with:\n          to: html\n\n      - name: Set up Git\n        run: |\n          git config --local user.email \"actions@github.com\"\n          git config --local user.name \"GitHub Actions\"\n\n      - name: Commit all changes and push\n        run: |\n          git add -A && git commit -m 'Build site' || echo \"No changes to commit\"\n          git push origin || echo \"No changes to commit\""
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/Intro.html",
    "href": "content/NMFS_OpenSciDirections/Intro.html",
    "title": "NOAA quarto simple with R",
    "section": "",
    "text": "This is a template for a simple Quarto website (type: website). It looks like a html book (type: book) but unlike the book type it only has html format and you will not have the download options. type: website is a common format for documentation.\nThe repo includes a GitHub Action that will build the website automatically when you make changes to the files. The webpage will use the gh-pages branch. Serving the website files from this branch is a common way to keep all the website files from cluttering your main branch.\nWarning: Check that the settings will allow the GitHub Action to run. See the instructions below under “GitHub Set-up”. Scroll down to the troubleshooting section if the website is not built by the GitHub Action.\nNote: The GitHub Action installs R so you can render qmd files with R code. You will need to edit to install Python or Julia if your qmd uses those instead. If you have substantial computations, you don’t want to be re-running all the computations for files that didn’t change. Read about the freeze option for this situation. R users with complex reports with dependencies (so qmd B depends on qmd A or data file A) should be aware of the {targets} package which will help you keep track of files that need to be re-rendered due to changes in dependencies.\n\n\n\nClick the green “Use This Template” button to make a repository with this content. Make sure to make your repo public (since GitHub Pages doesn’t work on private repos unless you have a paid account) and check box to include all the branches (so that you get the gh-pages branch). \nTurn on GitHub Pages under Settings &gt; Pages . You will set pages to be made from the gh-pages branch and root directory. \nAllow GitHub Actions under Settings &gt; Actions &gt; General \nAllow GitHub Actions to write to the gh-pages branch. Scroll to the bottom under Settings &gt; Actions &gt; General, and make sure “Read and Write” is selected. \nEdit the repo description and Readme to add a link to the webpage. When you edit the description, you will see the link url in the url box or you can click on the Actions tab or the Settings &gt; Pages page to find the url to the Quarto website\n\n\n\n\n\nEdit the qmd or md files in the content folder. qmd files can include code (R, Python, Julia) and lots of Quarto markdown bells and whistles (like call-outs, cross-references, auto-citations and much more).\nAdd the files to _quarto.yml\n\n\n\n\nThe most common trouble users run into is that the book is not rendering. Check the following:\n\nThe gh-pages branch does not exist. If you forgot to check the check box to include all the branches when you created the repo from the template then it won’t exist. The Action will fail if the gh-pages branch does not already exist. You can create the branch and then push a change to main to trigger the Action to run again.\nThe GitHub Pages has not been set. You need to go to Pages under settings, and set Pages to build from the gh-pages branch.\nYou did not allow GitHub Actions to run and/or did not give read/write permission. Go to Settings &gt; Actions &gt; General, and make sure Actions are allowed (top section) and they have read/write permission (bottom section).\nYou did not push a change to the main branch. The Action is triggered by a push to main, so try making an edit to README.md and pushing that change."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/Intro.html#github-set-up",
    "href": "content/NMFS_OpenSciDirections/Intro.html#github-set-up",
    "title": "NOAA quarto simple with R",
    "section": "",
    "text": "Click the green “Use This Template” button to make a repository with this content. Make sure to make your repo public (since GitHub Pages doesn’t work on private repos unless you have a paid account) and check box to include all the branches (so that you get the gh-pages branch). \nTurn on GitHub Pages under Settings &gt; Pages . You will set pages to be made from the gh-pages branch and root directory. \nAllow GitHub Actions under Settings &gt; Actions &gt; General \nAllow GitHub Actions to write to the gh-pages branch. Scroll to the bottom under Settings &gt; Actions &gt; General, and make sure “Read and Write” is selected. \nEdit the repo description and Readme to add a link to the webpage. When you edit the description, you will see the link url in the url box or you can click on the Actions tab or the Settings &gt; Pages page to find the url to the Quarto website"
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/Intro.html#customize",
    "href": "content/NMFS_OpenSciDirections/Intro.html#customize",
    "title": "NOAA quarto simple with R",
    "section": "",
    "text": "Edit the qmd or md files in the content folder. qmd files can include code (R, Python, Julia) and lots of Quarto markdown bells and whistles (like call-outs, cross-references, auto-citations and much more).\nAdd the files to _quarto.yml"
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/Intro.html#troubleshooting-builds",
    "href": "content/NMFS_OpenSciDirections/Intro.html#troubleshooting-builds",
    "title": "NOAA quarto simple with R",
    "section": "",
    "text": "The most common trouble users run into is that the book is not rendering. Check the following:\n\nThe gh-pages branch does not exist. If you forgot to check the check box to include all the branches when you created the repo from the template then it won’t exist. The Action will fail if the gh-pages branch does not already exist. You can create the branch and then push a change to main to trigger the Action to run again.\nThe GitHub Pages has not been set. You need to go to Pages under settings, and set Pages to build from the gh-pages branch.\nYou did not allow GitHub Actions to run and/or did not give read/write permission. Go to Settings &gt; Actions &gt; General, and make sure Actions are allowed (top section) and they have read/write permission (bottom section).\nYou did not push a change to the main branch. The Action is triggered by a push to main, so try making an edit to README.md and pushing that change."
  },
  {
    "objectID": "content/AnalysisMethods.html",
    "href": "content/AnalysisMethods.html",
    "title": "Analysis Methods",
    "section": "",
    "text": "An analysis methods section is required and should include the following information;\n\nData Prep and Archive\n\nData prep (decompressing, creating LTSAs, decimating, etc.)\n\nSAEL example\n\nData quality checks (QAQC scripts)\n\nSAEL example\n\nData upload steps\n\nIf you have a internal storage include directions here on where data should be stored and in what format\nYou can also include a data managment structure with standardized naming and storage/folder structures\nSAEL example\n\n\nAnalysis methods for each species, group, or sound source\n\nYou can break this down by baleen and toothed whales, soundscapes, etc.\nEach section should include detailed and reproducible methods that anybody can recreate\n\n\nYou can also link to a separate hardware repository if needed (SAEL example)\nGlider Lab Manual example",
    "crumbs": [
      "Software & Analysis Methods",
      "Analysis Methods"
    ]
  },
  {
    "objectID": "content/SI coord/SI_Coordination.html#overview",
    "href": "content/SI coord/SI_Coordination.html#overview",
    "title": "IRA PAM Strategic Initiative Coordination",
    "section": "Overview",
    "text": "Overview\nThis page serves as a landing page to coordinate progress towards the Passive Acoustic Monitoring Strategic Initiative (PAM SI). Included below are important links to identify open action items, review priority project descriptions and working group meeting notes, as well as track progress and issues through GitHub projects.\nThe PAM SI Team has identified eight priority projects that combined work towards two overarching goals: (1) National Data & Analysis Integration and (2) Infrastructure Development & Efficiency. Progress towards these goals will implement transformational activities that will significantly change the way in which we collect, analyze, and make PAM data accessible for answering mission critical questions.",
    "crumbs": [
      "SI Coordination"
    ]
  },
  {
    "objectID": "content/SI coord/SI_Coordination.html#important-links",
    "href": "content/SI coord/SI_Coordination.html#important-links",
    "title": "IRA PAM Strategic Initiative Coordination",
    "section": "Important Links",
    "text": "Important Links\n\nPAM SI Active Action Items tracker\nMarch 2024 Workshop Report\nPAM SI Progress Dashboard\nGitHub Projects (* More details to come - this link will only work once you become a member of the NMFS OST GitHub Organization)\nPAM SI Projects Google Folder\nNotes from Bi-weekly SI Team Meetings",
    "crumbs": [
      "SI Coordination"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/NCEI_archiving.html",
    "href": "content/SI coord/PAM_priority_projects/NCEI_archiving.html",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal: Build efficient workflows to archive large volumes of NMFS PAM data and meet the projected data growth needs\nTeam Leads: Carrie Wall Bell (NCEI), Jason Gedamke (OST)",
    "crumbs": [
      "PAM SI Priority Projects",
      "NCEI Archiving"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/NCEI_archiving.html#ncei-archiving",
    "href": "content/SI coord/PAM_priority_projects/NCEI_archiving.html#ncei-archiving",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal: Build efficient workflows to archive large volumes of NMFS PAM data and meet the projected data growth needs\nTeam Leads: Carrie Wall Bell (NCEI), Jason Gedamke (OST)",
    "crumbs": [
      "PAM SI Priority Projects",
      "NCEI Archiving"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/Nationaldecision_supporttool.html",
    "href": "content/SI coord/PAM_priority_projects/Nationaldecision_supporttool.html",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal: Develop a National PAM Decision Support tool to facilitate informed decision making regarding anthropogenic activity and long term trends\nTeam Leads (all NEFSC): Sofie Van Parijs, Genevieve Davis, Jeff Walker",
    "crumbs": [
      "PAM SI Priority Projects",
      "National Decision Support Tool"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/Nationaldecision_supporttool.html#nmfs-pam-google-cloud-project-2",
    "href": "content/SI coord/PAM_priority_projects/Nationaldecision_supporttool.html#nmfs-pam-google-cloud-project-2",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal: Develop a National PAM Decision Support tool to facilitate informed decision making regarding anthropogenic activity and long term trends\nTeam Leads (all NEFSC): Sofie Van Parijs, Genevieve Davis, Jeff Walker",
    "crumbs": [
      "PAM SI Priority Projects",
      "National Decision Support Tool"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/Soundscapes.html",
    "href": "content/SI coord/PAM_priority_projects/Soundscapes.html",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal: Facilitate cross-agency, region, and platform soundscape comparisons by quantifying soundscape metrics for priority datasets and generate decision support tools that integrate soundscape visualizations with multiple data types.\nTeam Leads: Samara Haver (PMEL), Megan McKenna (ONMS)",
    "crumbs": [
      "PAM SI Priority Projects",
      "Soundscapes"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/Soundscapes.html#soundscape-analysis-metrics-and-tools",
    "href": "content/SI coord/PAM_priority_projects/Soundscapes.html#soundscape-analysis-metrics-and-tools",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal: Facilitate cross-agency, region, and platform soundscape comparisons by quantifying soundscape metrics for priority datasets and generate decision support tools that integrate soundscape visualizations with multiple data types.\nTeam Leads: Samara Haver (PMEL), Megan McKenna (ONMS)",
    "crumbs": [
      "PAM SI Priority Projects",
      "Soundscapes"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/Openscience_infosharing.html",
    "href": "content/SI coord/PAM_priority_projects/Openscience_infosharing.html",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal: Enhance National PAM collaboration among the regions by facilitating an open science culture and creating the infrastructure for information sharing on GitHub.\nTeam Leads: Becca Van Hoeck (NEFSC), Shannon Rankin (SWFSC)",
    "crumbs": [
      "PAM SI Priority Projects",
      "Open science Information Sharing"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/Openscience_infosharing.html#national-pam-coordination-and-sharing",
    "href": "content/SI coord/PAM_priority_projects/Openscience_infosharing.html#national-pam-coordination-and-sharing",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal: Enhance National PAM collaboration among the regions by facilitating an open science culture and creating the infrastructure for information sharing on GitHub.\nTeam Leads: Becca Van Hoeck (NEFSC), Shannon Rankin (SWFSC)",
    "crumbs": [
      "PAM SI Priority Projects",
      "Open science Information Sharing"
    ]
  },
  {
    "objectID": "content/OpenScience.html",
    "href": "content/OpenScience.html",
    "title": "Open Science",
    "section": "",
    "text": "This section is optional but we recommend creating this place to point to the Open Science repository.\nSAEL Example",
    "crumbs": [
      "Optional Pages",
      "Open Science"
    ]
  },
  {
    "objectID": "content/Inventory.html",
    "href": "content/Inventory.html",
    "title": "Inventory",
    "section": "",
    "text": "An inventory page is highly recommended to keep track of equipment, loans, and gear beingin the field. This can be a link to a Google sheet or embedded in the website\n\nSAEL Lab Example"
  },
  {
    "objectID": "content/Reporting.html",
    "href": "content/Reporting.html",
    "title": "Reporting",
    "section": "",
    "text": "his is a required page and should include any templates you have created for reporting within NOAA or to other agencies.\nExamples include NEFSC PAM data reporting templates and standard report formats for a few different agencies/species (right whales, Australian Marine Parks).",
    "crumbs": [
      "Reporting"
    ]
  },
  {
    "objectID": "content/Reporting.html#templates",
    "href": "content/Reporting.html#templates",
    "title": "Reporting",
    "section": "",
    "text": "his is a required page and should include any templates you have created for reporting within NOAA or to other agencies.\nExamples include NEFSC PAM data reporting templates and standard report formats for a few different agencies/species (right whales, Australian Marine Parks).",
    "crumbs": [
      "Reporting"
    ]
  },
  {
    "objectID": "content/Reporting.html#permits",
    "href": "content/Reporting.html#permits",
    "title": "Reporting",
    "section": "Permits",
    "text": "Permits\nYou should also include any permit reporting guidelines here\n\nPermits and Permit Reporting Guidelines\n\nInclude permit numbers and links to your centers/groups permits\nInclude directions for permit reporting (Protected species, National Marine Sanctuaries, Navy, Fish and Wildlife, etc)\nYou can include links to past permit reports (these can be private google drive folders if needed)\nSAEL example",
    "crumbs": [
      "Reporting"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "National Passive Acoustic Monitoring Network",
    "section": "",
    "text": "NOAA Fisheries’ PAM programs collect underwater sound recordings of the marine environment. Identification of the sounds produced by protected marine mammal species, fishes, humans, or the environment allows for an understanding of marine soundscapes and provides information on changes in species distribution, behavior and/or density. The technological revolution in PAM over the past decade has allowed both acoustic recorders and analytical approaches to increasingly become an integral part of NOAA Fisheries core science mission. PAM’s capacity for creating long term time series makes it an ideal approach for evaluating changes in species stocks, ecosystem interactions, and climate change.\nThere are seven NOAA Fisheries PAM programs including each regional Science Center and the Office of Science & Technology’s Ocean Acoustic Program. This repository serves to enhance National PAM collaboration within NOAA Fisheries and our partners through a common GitHub structure. Each of the regional science centers is in the process of establishing a region specific landing page that mimics the structure of this National page.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "content/DataManagement.html",
    "href": "content/DataManagement.html",
    "title": "Data Management",
    "section": "",
    "text": "A data management section is required and should include the following information;\n\nData Archive Methods\n\nInformation on where your data is archived (PACM, NCEI, Tethys, Internal databases, etc)\nSAEL Example\n\nSpecies reference guide for your region\n\nDevelop a species and call type library for your region\nThis can include spectrograms of calls and sound clips\nPIFSC working on this, use them as an example once finalized\nSAEL Example\n\nMedia\n\nLinks to sound archives, media archives, web sites, blogs, etc.\nSAEL Example\n\n\nThis can be a section with subpages or a qmd\nGlider Lab Manual",
    "crumbs": [
      "Data Management"
    ]
  },
  {
    "objectID": "content/PublicationsPresentations.html",
    "href": "content/PublicationsPresentations.html",
    "title": "Publications and Presentations",
    "section": "",
    "text": "This is an optional page but is a great opportunity to highlight some of your publications and presentations.\nSAEL example (add once this page is corrected)",
    "crumbs": [
      "Optional Pages",
      "Publications and Presentations"
    ]
  },
  {
    "objectID": "content/SI coord/Openscapes.html",
    "href": "content/SI coord/Openscapes.html",
    "title": "Openscapes",
    "section": "",
    "text": "Openscapes is an initiative focused on promoting open and reproducible science, while fostering collaboration, transparency, and accessibility among reseachers. The PAM SI Team will have representatives from every fisheries center participating in the Openscapes Fall 2024 cohort.\nOur goals include developing the NMFS PAM sharing structure in real time (national and regional lab manuals), building foundational open science knowledge, and sharing the lessons learned with our broader science center PAM groups",
    "crumbs": [
      "SI Coordination",
      "Openscapes"
    ]
  },
  {
    "objectID": "content/SI coord/Openscapes.html#goals",
    "href": "content/SI coord/Openscapes.html#goals",
    "title": "Openscapes",
    "section": "",
    "text": "Openscapes is an initiative focused on promoting open and reproducible science, while fostering collaboration, transparency, and accessibility among reseachers. The PAM SI Team will have representatives from every fisheries center participating in the Openscapes Fall 2024 cohort.\nOur goals include developing the NMFS PAM sharing structure in real time (national and regional lab manuals), building foundational open science knowledge, and sharing the lessons learned with our broader science center PAM groups",
    "crumbs": [
      "SI Coordination",
      "Openscapes"
    ]
  },
  {
    "objectID": "content/SI coord/Openscapes.html#notes",
    "href": "content/SI coord/Openscapes.html#notes",
    "title": "Openscapes",
    "section": "Notes",
    "text": "Notes\nAll meeting notes and Openscapes related documents will be accessible in the PAM SI Openscapes Google Drive Folder",
    "crumbs": [
      "SI Coordination",
      "Openscapes"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/Climate_LTtrends.html",
    "href": "content/SI coord/PAM_priority_projects/Climate_LTtrends.html",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal: Integration of PAM and environmental data to support climate change investigations by developing new tools that can be applied to all regions and species of interest.\nTeam Leads: Genevieve Davis (NEFSC), Catherine Berchok (AFSC)",
    "crumbs": [
      "PAM SI Priority Projects",
      "Climate & Long-Term Trends"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/Climate_LTtrends.html#pam-climate-long-term-trends",
    "href": "content/SI coord/PAM_priority_projects/Climate_LTtrends.html#pam-climate-long-term-trends",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal: Integration of PAM and environmental data to support climate change investigations by developing new tools that can be applied to all regions and species of interest.\nTeam Leads: Genevieve Davis (NEFSC), Catherine Berchok (AFSC)",
    "crumbs": [
      "PAM SI Priority Projects",
      "Climate & Long-Term Trends"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/PAM GCP Technical System Documentation.html",
    "href": "content/SI coord/PAM_priority_projects/PAM GCP Technical System Documentation.html",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "PAM GCP Technical System Documentation\nOverview: Summary of key decisions, technical system set-up, and use expectations for using software applications in the PAM GCP. This document is an initial way to collaborate on developing the documentation and will be transitioned to the National PAM Network GitHub once folks have access.\nThe acoustics SI and project design philosophy:\nThe ggn-nmfs-pamdata-prod-1 (“pamdata”) GCP project is designed to encompass the requirements of the PAM SI, while best prioritizing the wants and needs of the end-users and use cases, and staying near best admin practices for NMFS OCIO GCP. The relevant objectives of the PAM acoustics SI include acoustic data storage across NMFS, and passive acoustic monitoring applications that generally feed from this data. The primary end-users of the system include data owners and users, and application owners, developers, and users.\nPermissions structure:\nA principle and role based structure was designed for project capabilities. By defining specific principle groups (project supervisor, application developer, etc) the project is resilient to changes in individual users. Roles are given to these principle groups- for example, the project supervisors principle group is given viewing roles for most of the resources in the project for their visibility.\nFor quick configuration and transparency during the dynamic early stages of the project, principle and role definitions are managed by a central “project admin” principle group via terraform. NMFS OCIO best practice recommends Terraform for more transparent project resource configuration and management, and this allows for simplicity and transparency.\nAlternatives: In the future, we may wish to delegate assignment of users to principle groups in a way that better resembles the true acoustics SI responsible parties (ie, supervisors can assign the project admin(s), data authorities can designate their respective data admin(s), etc). In the short term, this may result in too much unpredictability to the dynamic project.\nBelow are some of the currently defined principles for the project:\n\n\n\n\n\n\n\nPrinciple group name\nDefinition and roles\n\n\n\n\nProject admin\nHighest GCP admin role, controls project terraform (all principle, role, resource definitions)\n\n\nProject supervisors\nHighest SI role, has visibility across project resources, tells project admin what to do\n\n\nData authority\nResponsible party for a particular FMC data storage bucket\n\n\nData admin\nAdministrates the contents (write/delete) of a particular storage bucket\n\n\nApplication developer\nAccess to software development resources\n\n\n\nResources:\nThe pamdata project is expected to house PAM data from across NMFS, application development resources, and various applications (&lt;30) in various states of development. Sprawl is a serious threat, in particular since many end-users of the system (owners/authorities, supervisors, users) tend to understand the system through use of a web browser as opposed to filterable api calls. In other words, resource sprawl will lead to reduced understandability of the project across the PAM SI end users and is thus carefully considered.\nData resources:\nEach FMC has a distinct storage bucket for their data. This allows for some flexibility in data naming and easier isolation of permissions between FMCs. Principle groups that are designated here are data authorities (the data owner or responsible party, usually the PI of an FMC acoustics group), and the data admins (the technical users responsible for maintaining the contents of the storage bucket).\nThe browser allows for easy viewing of the storage buckets such that non-technical users can easily interpret the current state of the data across the NMFS FMCs. However, the tool cannot distinguish the FMC buckets from application buckets, and in order to maintain easy interpretability applications will be encouraged to consolidate to fewer buckets as appropriate. Currently, three additional buckets outside of the FMC data buckets exist: the terraform state bucket, an application intermediate bucket, and an application output bucket.\nDevelopment resources:\nThe following resources have been stood up for application development:\nHardened docker image/server: Based on NMFS hardened linux container and preloaded with docker. I developed an imagining pipeline for this, meaning it will be easy to keep up to date and we can make as many copies of this as developers need them. Developing on this instead of locally will be a little closer to cloud and streamlines and simplifies some assumptions. Please make sure any developers working on containers understand this option exists and the advantages in doing development here (hardware flexibility, more similar to production, built in permissions w/o key management, etc).\nDocker registry: This is where container images will be placed (whether we build or import them), and it is a key backbone of a variety of GCP container orchestration services.\nApplication storage buckets: There are two new storage buckets, pamdata-app-intermediates and pamdata-app-outputs. Some of the time applications will need their own specific tiering and lifecycle, but I wanted to start with just these two, especially for early development, given that they are visible along with the FMC data buckets and we tend to like to use the console as a browsing tool to keep track of these. Keeping it to two, and dividing permissions by prefix, will keep the bucket display from getting too muddied.\nNetworking: Created networks and subnets - one for application and development machines, which require ssh and NAT internet connectivity, and one for batch processing, which relies on only private google connectivity by default, but other connectivity can be added as a particular app might need."
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/Cloud_storage.html",
    "href": "content/SI coord/PAM_priority_projects/Cloud_storage.html",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal:\nDemonstrate a scalable and cost-effective cloud-based workflow to modernize NMFS PAM operations and support the protected species mission\nTeam Leads:\nSofie Van Parijs (NEFSC), Dan Woodrich (AFSC)\n\n\n\nOverview: Summary of key decisions, technical system set-up, and use expectations for using software applications in the PAM GCP. This document is an initial way to collaborate on developing the documentation and will be transitioned to the National PAM Network GitHub once folks have access.\n\n\nThe ggn-nmfs-pamdata-prod-1 (“pamdata”) GCP project is designed to encompass the requirements of the PAM SI, while best prioritizing the wants and needs of the end-users and use cases, and staying near best admin practices for NMFS OCIO GCP. The relevant objectives of the PAM acoustics SI include acoustic data storage across NMFS, and passive acoustic monitoring applications that generally feed from this data. The primary end-users of the system include data owners and users, and application owners, developers, and users.\n\n\n\nA principle and role based structure was designed for project capabilities. By defining specific principle groups (project supervisor, application developer, etc) the project is resilient to changes in individual users. Roles are given to these principle groups- for example, the project supervisors principle group is given viewing roles for most of the resources in the project for their visibility.\nFor quick configuration and transparency during the dynamic early stages of the project, principle and role definitions are managed by a central “project admin” principle group via terraform. NMFS OCIO best practice recommends Terraform for more transparent project resource configuration and management, and this allows for simplicity and transparency.\nAlternatives: In the future, we may wish to delegate assignment of users to principle groups in a way that better resembles the true acoustics SI responsible parties (ie, supervisors can assign the project admin(s), data authorities can designate their respective data admin(s), etc). In the short term, this may result in too much unpredictability to the dynamic project.\nBelow are some of the currently defined principles for the project:\n\n\n\n\n\n\n\nPrinciple group name\nDefinition and roles\n\n\n\n\nProject admin\nHighest GCP admin role, controls project terraform (all principle, role, resource definitions)\n\n\nProject supervisors\nHighest SI role, has visibility across project resources, tells project admin what to do\n\n\nData authority\nResponsible party for a particular FMC data storage bucket\n\n\nData admin\nAdministrates the contents (write/delete) of a particular storage bucket\n\n\nApplication developer\nAccess to software development resources\n\n\n\n\n\n\nThe pamdata project is expected to house PAM data from across NMFS, application development resources, and various applications (&lt;30) in various states of development. Sprawl is a serious threat, in particular since many end-users of the system (owners/authorities, supervisors, users) tend to understand the system through use of a web browser as opposed to filterable api calls. In other words, resource sprawl will lead to reduced understandability of the project across the PAM SI end users and is thus carefully considered.\n\n\n\nEach FMC has a distinct storage bucket for their data. This allows for some flexibility in data naming and easier isolation of permissions between FMCs. Principle groups that are designated here are data authorities (the data owner or responsible party, usually the PI of an FMC acoustics group), and the data admins (the technical users responsible for maintaining the contents of the storage bucket).\nThe browser allows for easy viewing of the storage buckets such that non-technical users can easily interpret the current state of the data across the NMFS FMCs. However, the tool cannot distinguish the FMC buckets from application buckets, and in order to maintain easy interpretability applications will be encouraged to consolidate to fewer buckets as appropriate. Currently, three additional buckets outside of the FMC data buckets exist: the terraform state bucket, an application intermediate bucket, and an application output bucket.\n\n\n\nThe following resources have been stood up for application development:\nHardened docker image/server:\nBased on NMFS hardened linux container and preloaded with docker. I developed an imagining pipeline for this, meaning it will be easy to keep up to date and we can make as many copies of this as developers need them. Developing on this instead of locally will be a little closer to cloud and streamlines and simplifies some assumptions. Please make sure any developers working on containers understand this option exists and the advantages in doing development here (hardware flexibility, more similar to production, built in permissions w/o key management, etc).\nDocker registry:\nThis is where container images will be placed (whether we build or import them), and it is a key backbone of a variety of GCP container orchestration services.\nApplication storage buckets:\nThere are two new storage buckets, pamdata-app-intermediates and pamdata-app-outputs. Some of the time applications will need their own specific tiering and lifecycle, but I wanted to start with just these two, especially for early development, given that they are visible along with the FMC data buckets and we tend to like to use the console as a browsing tool to keep track of these. Keeping it to two, and dividing permissions by prefix, will keep the bucket display from getting too muddied.\nNetworking:\nCreated networks and subnets - one for application and development machines, which require ssh and NAT internet connectivity, and one for batch processing, which relies on only private google connectivity by default, but other connectivity can be added as a particular app might need.\n\n\n\n\n\n\n\n\n\nASFC was able to upload 100TB of acoustic data to our GCP bucket over the internet connection in our science center (in Seattle) in a three week upload window with low operator effort, representing our whole primary acoustic data collection.\n\n\n\n\nOur research group committed two computers with normal user permissions in the AFSC data center to upload data from the AFSC LAN to our pamdata bucket. These two computers ran a simple script, which was written in R and wrapped calls to the GCP ‘gsutil’ tool. The script was very simple, about 50 lines. The script instructed the computers to only initiate uploads between the hours of 7pm and 6am on weekdays and constantly on weekends. The R sessions were logged so we could identify any early termination that might have resulted in partial or corrupted uploads. Additional process will be designed to check that the data was uploaded in full.\n\n\n\n\nAFSC IT would have been notified by the NMFS network team if the traffic were considered disruptive. They would have traced the traffic to the machines under my user name, and contacted me to ask questions. This not happening suggests that the traffic was a non-issue. Scheduling traffic within off-hours (nights and weekends) prevents throttling normal user traffic during working hours, and staying within these confines is respectful and normal practice for NMFS IT groups. We did not notify AFSC IT or the NMFS network team as we wanted to test the impact of this traffic empirically, but going forward, especially with multiple FMCs performing uploads concurrently, we advise approving the traffic with FMC & NMFS IT.\n\n\n\n\nDan Woodrich daniel.woodrich@noaa.gov if you would like to explore a similar process for your FMC acoustic data.\nR script: \n\nis_weekday = function(x){\n  weekdays = c('Thursday','Friday','Monday','Tuesday','Wednesday')\n  return(weekdays(x) %in% weekdays)\n}\n\nis_after_hours= function(x){\n  return(as.integer(format(x,\"%H\")) &lt; 6 | as.integer(format(x,\"%H\")) &gt; 18)\n}\n\n#cloud data upload. This assumes you are uploading bottom_mounted data , and just uploads the full content of each folder below the 'moorings' folder. Adapt the logic to your needs but note renaming / reorganizing is more complex. \n\nmy_fmc_bucket_name = 'afsc-1'\nmy_top_level_data_path = \"//161.55.120.117/NMML_AcousticsData/Audio_Data/Waves\"\nmoorings = dir(my_top_level_data_path) #gets each subfolder of top level data path. \n\n#log the job\nsink(paste(\"//akc0ss-n086/NMML_CAEP_Acoustics/Detector/pam_si/upload_log_\",Sys.info()['nodename'],\".csv\",sep=\"\"), append=TRUE, split=TRUE)\n\nwork = list(1:200,201:length(moorings)) #in my case we had 435 moorings. \nnames(work) = c(\"computer1-name\",\"computer2-name\") #needs to match Sys.info()['nodename'] for computers you are using\nmoorings = moorings[work[[Sys.info()['nodename']]]]\n\nfor(mooring in moorings){\n  \n  #detect if it's a weekday during work hours, don't start a job. \n  while(is_weekday(Sys.time()) & !is_after_hours(Sys.time())){\n    cat(paste('waiting...',Sys.time(),\"\\n\"))\n    Sys.sleep(600) #wait 10 minutes until trying again. \n  }\n  \n  #gsutil needs to be installed on the system through Google Cloud SDK. If you can open up a command line and run 'gsutil help' and recieve a response, the below line will work.  \n  string = paste(\"gsutil -m cp -r \",my_top_level_data_path,mooring,\" gs://\",my_fmc_bucket_name,\"/bottom_mounted/\",mooring,sep=\"\")\n  cat(paste(\"started\",mooring,\"at\",Sys.time(),\"\\n\"))\n  system(string,intern=TRUE) \n  cat(paste(\"ended\",mooring,\"at\",Sys.time(),\"\\n\"))\n}\n\n\n\n\n\n\n\nEnable APIs - this has been completed that the console/project level and the checklist item can simply be marked as complete.\nAuthorize Service Acounts: Email Dan Woodrich daniel.woodrich@noaa.gov the link to the checklist so he can complete that step on your behalf",
    "crumbs": [
      "PAM SI Priority Projects",
      "Cloud Storage Solutions"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/Cloud_storage.html#nmfs-pam-google-cloud-project-1",
    "href": "content/SI coord/PAM_priority_projects/Cloud_storage.html#nmfs-pam-google-cloud-project-1",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal:\nDemonstrate a scalable and cost-effective cloud-based workflow to modernize NMFS PAM operations and support the protected species mission\nTeam Leads:\nSofie Van Parijs (NEFSC), Dan Woodrich (AFSC)\n\n\n\nOverview: Summary of key decisions, technical system set-up, and use expectations for using software applications in the PAM GCP. This document is an initial way to collaborate on developing the documentation and will be transitioned to the National PAM Network GitHub once folks have access.\n\n\nThe ggn-nmfs-pamdata-prod-1 (“pamdata”) GCP project is designed to encompass the requirements of the PAM SI, while best prioritizing the wants and needs of the end-users and use cases, and staying near best admin practices for NMFS OCIO GCP. The relevant objectives of the PAM acoustics SI include acoustic data storage across NMFS, and passive acoustic monitoring applications that generally feed from this data. The primary end-users of the system include data owners and users, and application owners, developers, and users.\n\n\n\nA principle and role based structure was designed for project capabilities. By defining specific principle groups (project supervisor, application developer, etc) the project is resilient to changes in individual users. Roles are given to these principle groups- for example, the project supervisors principle group is given viewing roles for most of the resources in the project for their visibility.\nFor quick configuration and transparency during the dynamic early stages of the project, principle and role definitions are managed by a central “project admin” principle group via terraform. NMFS OCIO best practice recommends Terraform for more transparent project resource configuration and management, and this allows for simplicity and transparency.\nAlternatives: In the future, we may wish to delegate assignment of users to principle groups in a way that better resembles the true acoustics SI responsible parties (ie, supervisors can assign the project admin(s), data authorities can designate their respective data admin(s), etc). In the short term, this may result in too much unpredictability to the dynamic project.\nBelow are some of the currently defined principles for the project:\n\n\n\n\n\n\n\nPrinciple group name\nDefinition and roles\n\n\n\n\nProject admin\nHighest GCP admin role, controls project terraform (all principle, role, resource definitions)\n\n\nProject supervisors\nHighest SI role, has visibility across project resources, tells project admin what to do\n\n\nData authority\nResponsible party for a particular FMC data storage bucket\n\n\nData admin\nAdministrates the contents (write/delete) of a particular storage bucket\n\n\nApplication developer\nAccess to software development resources\n\n\n\n\n\n\nThe pamdata project is expected to house PAM data from across NMFS, application development resources, and various applications (&lt;30) in various states of development. Sprawl is a serious threat, in particular since many end-users of the system (owners/authorities, supervisors, users) tend to understand the system through use of a web browser as opposed to filterable api calls. In other words, resource sprawl will lead to reduced understandability of the project across the PAM SI end users and is thus carefully considered.\n\n\n\nEach FMC has a distinct storage bucket for their data. This allows for some flexibility in data naming and easier isolation of permissions between FMCs. Principle groups that are designated here are data authorities (the data owner or responsible party, usually the PI of an FMC acoustics group), and the data admins (the technical users responsible for maintaining the contents of the storage bucket).\nThe browser allows for easy viewing of the storage buckets such that non-technical users can easily interpret the current state of the data across the NMFS FMCs. However, the tool cannot distinguish the FMC buckets from application buckets, and in order to maintain easy interpretability applications will be encouraged to consolidate to fewer buckets as appropriate. Currently, three additional buckets outside of the FMC data buckets exist: the terraform state bucket, an application intermediate bucket, and an application output bucket.\n\n\n\nThe following resources have been stood up for application development:\nHardened docker image/server:\nBased on NMFS hardened linux container and preloaded with docker. I developed an imagining pipeline for this, meaning it will be easy to keep up to date and we can make as many copies of this as developers need them. Developing on this instead of locally will be a little closer to cloud and streamlines and simplifies some assumptions. Please make sure any developers working on containers understand this option exists and the advantages in doing development here (hardware flexibility, more similar to production, built in permissions w/o key management, etc).\nDocker registry:\nThis is where container images will be placed (whether we build or import them), and it is a key backbone of a variety of GCP container orchestration services.\nApplication storage buckets:\nThere are two new storage buckets, pamdata-app-intermediates and pamdata-app-outputs. Some of the time applications will need their own specific tiering and lifecycle, but I wanted to start with just these two, especially for early development, given that they are visible along with the FMC data buckets and we tend to like to use the console as a browsing tool to keep track of these. Keeping it to two, and dividing permissions by prefix, will keep the bucket display from getting too muddied.\nNetworking:\nCreated networks and subnets - one for application and development machines, which require ssh and NAT internet connectivity, and one for batch processing, which relies on only private google connectivity by default, but other connectivity can be added as a particular app might need.\n\n\n\n\n\n\n\n\n\nASFC was able to upload 100TB of acoustic data to our GCP bucket over the internet connection in our science center (in Seattle) in a three week upload window with low operator effort, representing our whole primary acoustic data collection.\n\n\n\n\nOur research group committed two computers with normal user permissions in the AFSC data center to upload data from the AFSC LAN to our pamdata bucket. These two computers ran a simple script, which was written in R and wrapped calls to the GCP ‘gsutil’ tool. The script was very simple, about 50 lines. The script instructed the computers to only initiate uploads between the hours of 7pm and 6am on weekdays and constantly on weekends. The R sessions were logged so we could identify any early termination that might have resulted in partial or corrupted uploads. Additional process will be designed to check that the data was uploaded in full.\n\n\n\n\nAFSC IT would have been notified by the NMFS network team if the traffic were considered disruptive. They would have traced the traffic to the machines under my user name, and contacted me to ask questions. This not happening suggests that the traffic was a non-issue. Scheduling traffic within off-hours (nights and weekends) prevents throttling normal user traffic during working hours, and staying within these confines is respectful and normal practice for NMFS IT groups. We did not notify AFSC IT or the NMFS network team as we wanted to test the impact of this traffic empirically, but going forward, especially with multiple FMCs performing uploads concurrently, we advise approving the traffic with FMC & NMFS IT.\n\n\n\n\nDan Woodrich daniel.woodrich@noaa.gov if you would like to explore a similar process for your FMC acoustic data.\nR script: \n\nis_weekday = function(x){\n  weekdays = c('Thursday','Friday','Monday','Tuesday','Wednesday')\n  return(weekdays(x) %in% weekdays)\n}\n\nis_after_hours= function(x){\n  return(as.integer(format(x,\"%H\")) &lt; 6 | as.integer(format(x,\"%H\")) &gt; 18)\n}\n\n#cloud data upload. This assumes you are uploading bottom_mounted data , and just uploads the full content of each folder below the 'moorings' folder. Adapt the logic to your needs but note renaming / reorganizing is more complex. \n\nmy_fmc_bucket_name = 'afsc-1'\nmy_top_level_data_path = \"//161.55.120.117/NMML_AcousticsData/Audio_Data/Waves\"\nmoorings = dir(my_top_level_data_path) #gets each subfolder of top level data path. \n\n#log the job\nsink(paste(\"//akc0ss-n086/NMML_CAEP_Acoustics/Detector/pam_si/upload_log_\",Sys.info()['nodename'],\".csv\",sep=\"\"), append=TRUE, split=TRUE)\n\nwork = list(1:200,201:length(moorings)) #in my case we had 435 moorings. \nnames(work) = c(\"computer1-name\",\"computer2-name\") #needs to match Sys.info()['nodename'] for computers you are using\nmoorings = moorings[work[[Sys.info()['nodename']]]]\n\nfor(mooring in moorings){\n  \n  #detect if it's a weekday during work hours, don't start a job. \n  while(is_weekday(Sys.time()) & !is_after_hours(Sys.time())){\n    cat(paste('waiting...',Sys.time(),\"\\n\"))\n    Sys.sleep(600) #wait 10 minutes until trying again. \n  }\n  \n  #gsutil needs to be installed on the system through Google Cloud SDK. If you can open up a command line and run 'gsutil help' and recieve a response, the below line will work.  \n  string = paste(\"gsutil -m cp -r \",my_top_level_data_path,mooring,\" gs://\",my_fmc_bucket_name,\"/bottom_mounted/\",mooring,sep=\"\")\n  cat(paste(\"started\",mooring,\"at\",Sys.time(),\"\\n\"))\n  system(string,intern=TRUE) \n  cat(paste(\"ended\",mooring,\"at\",Sys.time(),\"\\n\"))\n}\n\n\n\n\n\n\n\nEnable APIs - this has been completed that the console/project level and the checklist item can simply be marked as complete.\nAuthorize Service Acounts: Email Dan Woodrich daniel.woodrich@noaa.gov the link to the checklist so he can complete that step on your behalf",
    "crumbs": [
      "PAM SI Priority Projects",
      "Cloud Storage Solutions"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/Pacific_glider.html",
    "href": "content/SI coord/PAM_priority_projects/Pacific_glider.html",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal: Develop R2O plan intended to serve all regions to integrate PAM gliders into assessment missions, reducing shiptime needs.\nTeam Leads: Erin Oleson (PIFSC), Shannon Rankin (SWFSC), UxS SI",
    "crumbs": [
      "PAM SI Priority Projects",
      "Pacific Glider R2O"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/Pacific_glider.html#accelerating-pacific-wide-pam-glider-operations",
    "href": "content/SI coord/PAM_priority_projects/Pacific_glider.html#accelerating-pacific-wide-pam-glider-operations",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal: Develop R2O plan intended to serve all regions to integrate PAM gliders into assessment missions, reducing shiptime needs.\nTeam Leads: Erin Oleson (PIFSC), Shannon Rankin (SWFSC), UxS SI",
    "crumbs": [
      "PAM SI Priority Projects",
      "Pacific Glider R2O"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/Stock_Assessments.html",
    "href": "content/SI coord/PAM_priority_projects/Stock_Assessments.html",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal: Advance the accuracy of stock assessments to capture seasonal and long-term changes using glider PAM datasets.\nTeam Leads: Erin Oleson (PIFSC), Yvonne Barkley (PIFSC)",
    "crumbs": [
      "PAM SI Priority Projects",
      "Stock Assessments"
    ]
  },
  {
    "objectID": "content/SI coord/PAM_priority_projects/Stock_Assessments.html#pam-stock-assessments",
    "href": "content/SI coord/PAM_priority_projects/Stock_Assessments.html#pam-stock-assessments",
    "title": "NOAA quarto simple",
    "section": "",
    "text": "Goal: Advance the accuracy of stock assessments to capture seasonal and long-term changes using glider PAM datasets.\nTeam Leads: Erin Oleson (PIFSC), Yvonne Barkley (PIFSC)",
    "crumbs": [
      "PAM SI Priority Projects",
      "Stock Assessments"
    ]
  },
  {
    "objectID": "content/LabManagement.html",
    "href": "content/LabManagement.html",
    "title": "Lab Management",
    "section": "",
    "text": "A lab management section is required and should include the following information;\n\nSafety\nInventory\nHardware"
  },
  {
    "objectID": "content/Software.html",
    "href": "content/Software.html",
    "title": "Software",
    "section": "",
    "text": "A software section is required and should include the following information;\n\nList of software you use and their applications (R, Matlab/Triton, Python, PAMGuard, Raven, etc.)\nSoftware packages or tools your team has built (PAMPal, PAMmisc, Banter, PAMscapes, Driftwatch, etc.)\n\nSAEL example",
    "crumbs": [
      "Software & Analysis Methods",
      "Software"
    ]
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/code.html",
    "href": "content/NMFS_OpenSciDirections/code.html",
    "title": "Rendering with Code",
    "section": "",
    "text": "You can have code (R, Python or Julia) in your qmd file. You will need to have these installed on your local computer, but presumably you do already if you are adding code to your qmd files.\nx &lt;- c(5, 15, 25, 35, 45, 55)\ny &lt;- c(5, 20, 14, 32, 22, 38)\nlm(x ~ y)\n\n\nCall:\nlm(formula = x ~ y)\n\nCoefficients:\n(Intercept)            y  \n      1.056        1.326"
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/code.html#modify-the-github-action",
    "href": "content/NMFS_OpenSciDirections/code.html#modify-the-github-action",
    "title": "Rendering with Code",
    "section": "Modify the GitHub Action",
    "text": "Modify the GitHub Action\nYou will need to change the GitHub Action in .github/workflows to install these and any needed packages in order for GitHub to be able to render your webpage. The GitHub Action install R since I used that in code.qmd. If you use Python or Julia instead, then you will need to update the GitHub Action to install those.\nIf getting the GitHub Action to work is too much hassle (and that definitely happens), you can alway render locally and publish to the gh-pages branch. If you do this, make sure to delete or rename the GitHub Action to something like\nrender-and-publish.old_yml\nso GitHub does not keep trying to run it. Nothing bad will happen if you don’t do this, but if you are not using the action (because it keeps failing), then you don’t need GitHub to run it."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/code.html#render-locally-and-publish-to-gh-pages-branch",
    "href": "content/NMFS_OpenSciDirections/code.html#render-locally-and-publish-to-gh-pages-branch",
    "title": "Rendering with Code",
    "section": "Render locally and publish to gh-pages branch",
    "text": "Render locally and publish to gh-pages branch\nTo render locally and push up to the gh-pages branch, open a terminal window and then cd to the directory with the Quarto project. Type this in the terminal:\nquarto render gh-pages"
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/Getting-Started.html",
    "href": "content/NMFS_OpenSciDirections/Getting-Started.html",
    "title": "Getting Started",
    "section": "",
    "text": "Open Science is a movement to make scientific research (including publications, data, software) transparent and accessible so that knowledge is shared. Here we will provide steps to get started; in future sections we will provide additional details on specific tasks/projects\n\nEmbrace the Open Science Mindset! Learn more about this approach and why it matters at Openscapes.org and the Openscapes Approach Guide.\nAdd Software Tools\n\nGithub Desktop\nRStudio (v2022.07.2 build 576 or later)\nR\nCreate a Github Login\n\nCreate a Repository using one of the following examples:\n\nCreate a Repository from a Template\n\nPAM Lab Manual Template- scroll down & follow directions ‘How to use this template’\nConsider one of Eli Holme’s templates\n\nCreate a New (or test) Repository in Github (see help here)\n\nClone your Test Repository to your local computer using Github Desktop:\n\nFile -&gt; Clone Repository -&gt; URL\nCopy URL of your Test Repository on Github and save to your Documents -&gt; Github folder using the defaults. See Introduction to Git/Github tutorial for more help.\n\nOpen project in RStudio. In the upper right hand corner of RStudio, select ‘New Project’ in the drop-down menu to add a new R Project from an Existing Project. Browse to find the appropriate folder in Documents-&gt; Github. In the lower right section of RStudio, select ‘Files’ and you will see the README.md file, which appears on the home page on your Github repository site.\nModify the README.md file. Open this file and add text and possibly a link to this document. Save the file. If you are using the latest version of RStudio (with quarto), you can modify your file using the Source Code or the Visual Editor. This is an RMarkdown file, so you can use R markdown language, or, if you prefer, you can use the visual editor which is more user-friendly. If you copy/paste an existing document into the visual editor, much of the existing formatting will be retained.\nCommit & Push to Github. Open your project in Github Desktop; Github desktop will identify the changes you made (refresh if necessary). At the bottom left, describe the modifications you made to the document, and then select ‘commit’. Once the commit goes through– select ‘Push to Origin’ at the top. This will push changes to your Github repository.\nOpen your Github repository and check out the changes on your README at the bottom of the page!\nAdopt this process as your daily habit of working on your projects locally and saving your data to Github.\n\nFor more information, see:\nIntroduction to Git/Github Tutorial (Eli Holmes, NMFS)\nGit for Humans (Alice Bartlett)\nHappy Git with R (Jenny Bryan)"
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/Getting-Started.html#getting-started-in-open-science",
    "href": "content/NMFS_OpenSciDirections/Getting-Started.html#getting-started-in-open-science",
    "title": "Getting Started",
    "section": "",
    "text": "Open Science is a movement to make scientific research (including publications, data, software) transparent and accessible so that knowledge is shared. Here we will provide steps to get started; in future sections we will provide additional details on specific tasks/projects\n\nEmbrace the Open Science Mindset! Learn more about this approach and why it matters at Openscapes.org and the Openscapes Approach Guide.\nAdd Software Tools\n\nGithub Desktop\nRStudio (v2022.07.2 build 576 or later)\nR\nCreate a Github Login\n\nCreate a Repository using one of the following examples:\n\nCreate a Repository from a Template\n\nPAM Lab Manual Template- scroll down & follow directions ‘How to use this template’\nConsider one of Eli Holme’s templates\n\nCreate a New (or test) Repository in Github (see help here)\n\nClone your Test Repository to your local computer using Github Desktop:\n\nFile -&gt; Clone Repository -&gt; URL\nCopy URL of your Test Repository on Github and save to your Documents -&gt; Github folder using the defaults. See Introduction to Git/Github tutorial for more help.\n\nOpen project in RStudio. In the upper right hand corner of RStudio, select ‘New Project’ in the drop-down menu to add a new R Project from an Existing Project. Browse to find the appropriate folder in Documents-&gt; Github. In the lower right section of RStudio, select ‘Files’ and you will see the README.md file, which appears on the home page on your Github repository site.\nModify the README.md file. Open this file and add text and possibly a link to this document. Save the file. If you are using the latest version of RStudio (with quarto), you can modify your file using the Source Code or the Visual Editor. This is an RMarkdown file, so you can use R markdown language, or, if you prefer, you can use the visual editor which is more user-friendly. If you copy/paste an existing document into the visual editor, much of the existing formatting will be retained.\nCommit & Push to Github. Open your project in Github Desktop; Github desktop will identify the changes you made (refresh if necessary). At the bottom left, describe the modifications you made to the document, and then select ‘commit’. Once the commit goes through– select ‘Push to Origin’ at the top. This will push changes to your Github repository.\nOpen your Github repository and check out the changes on your README at the bottom of the page!\nAdopt this process as your daily habit of working on your projects locally and saving your data to Github.\n\nFor more information, see:\nIntroduction to Git/Github Tutorial (Eli Holmes, NMFS)\nGit for Humans (Alice Bartlett)\nHappy Git with R (Jenny Bryan)"
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/organize.html",
    "href": "content/NMFS_OpenSciDirections/organize.html",
    "title": "Organize with Yaml",
    "section": "",
    "text": "Quarto Books are combinations of multiple documents (chapters) into a single manuscript in one or more formats (HTML, PDF, Word Doc, etc). Our example below is based on the PAM_template_lab_manual:\nindex.qmd- the index.qmd file is in the root director for your project, and serves as the Home Page for a website. This file is mandatory.\n_quarto.yml- the _quarto.yml is the configuration file for your project, and is also located in the root directory. The _quarto.yml provides information regarding overall formatting and structure of pages within the larger document.\nREADME.md- Markdown file that serves as the readme for the github repository.\ncontent folder- This folder contains the individual pages for your document. Alternative names for this folder are sometimes used, but we have found that the term ‘content’ is less confusing that frequently used alternatives. Here we recommend using this for consistency.\n\n\nYAML is a human-readable data serialization language commonly used for configuration files. YAML works with multiple programming languages, and also allows users to add comments to their data (useful for documentation). YAML does require very specific indentation, mapping, etc. It is helpful to use a yaml checker to be sure your yaml does not have errors.\nQuarto books/websites contain a _quarto.yml file, which is the website’s configuration file. It is essentially metadata for the website that includes the order that the pages/chapters will be in. This is where you organize your site. Here is a side-by-side example:\n\nLearn more, here."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/organize.html#how-to-organize-your-quarto-book",
    "href": "content/NMFS_OpenSciDirections/organize.html#how-to-organize-your-quarto-book",
    "title": "Organize with Yaml",
    "section": "",
    "text": "Quarto Books are combinations of multiple documents (chapters) into a single manuscript in one or more formats (HTML, PDF, Word Doc, etc). Our example below is based on the PAM_template_lab_manual:\nindex.qmd- the index.qmd file is in the root director for your project, and serves as the Home Page for a website. This file is mandatory.\n_quarto.yml- the _quarto.yml is the configuration file for your project, and is also located in the root directory. The _quarto.yml provides information regarding overall formatting and structure of pages within the larger document.\nREADME.md- Markdown file that serves as the readme for the github repository.\ncontent folder- This folder contains the individual pages for your document. Alternative names for this folder are sometimes used, but we have found that the term ‘content’ is less confusing that frequently used alternatives. Here we recommend using this for consistency.\n\n\nYAML is a human-readable data serialization language commonly used for configuration files. YAML works with multiple programming languages, and also allows users to add comments to their data (useful for documentation). YAML does require very specific indentation, mapping, etc. It is helpful to use a yaml checker to be sure your yaml does not have errors.\nQuarto books/websites contain a _quarto.yml file, which is the website’s configuration file. It is essentially metadata for the website that includes the order that the pages/chapters will be in. This is where you organize your site. Here is a side-by-side example:\n\nLearn more, here."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/organize.html#resources",
    "href": "content/NMFS_OpenSciDirections/organize.html#resources",
    "title": "Organize with Yaml",
    "section": "Resources",
    "text": "Resources\n\nYaml Checker\nQuarto Yaml Options (HTML)\nQuarto Book Structure"
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/add-content.html",
    "href": "content/NMFS_OpenSciDirections/add-content.html",
    "title": "Customize Content",
    "section": "",
    "text": "You can customize your content by (1) Modifying existing content, or (2) creating your own content. For examples, we will assume a folder structure such as that in the PAM Template Lab Manual."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/add-content.html#modify-existing-content",
    "href": "content/NMFS_OpenSciDirections/add-content.html#modify-existing-content",
    "title": "Customize Content",
    "section": "Modify Existing Content",
    "text": "Modify Existing Content\nHere are basic instructions for modifying existing content, such as the example pages provided in the PAM Template Lab Manual: 1) Ensure that you have cloned the Github Repository using Github Desktop, and that you have created an RStudio project, following directions outlined here.\n\nOpen your RStudio project (here we will assume it is a clone of the PAM Template Lab Manual), and navigate to the ‘content’ folder (lower right hand side of RStudio, Files Tab). As an example, we will change the “/content/Hardware.qmd” file. First, read the information in the page to understand the intended content. To start, we will organize different subheadings within this page.\nIdentify Sub-Headings. In this example, we will want to identify different types of Hardware used by our particular lab. In this example, we will want the following categories: “PAM Gliders”, “Drifting Recorders”, “Towed Arrays”, and “Handheld Hydrophones”.\n\nUsing the Source editor, use # to indicate Heading 1 style, ## for Heading 2 Style, etc.\nUsing the Visual editor, use the dropdown menu to select the Heading Style\n\nAdd Content. Most content will consist of text, with some images, hyperlinks, and occasional tables. To start, we recommend identifying the content you would like to put in there, and identify the Point of Contact (POC). As an example, we may put the following text:\nPOC: Jane Doe. General description of Hardware, links to online content (vendor specification page, relevant online content), instructions for build or maintain hardware (or links to that information), links to inventory, etc.\nOnce your outline is developed, fill in the content. IF someone else will collate the content– they can create it in a separate document to be copied/pasted here, or they can directly modify this page.\nIf you find you need separate pages for each sub-heading (instead of one long subheading), then create New Content, and link the new content to the _quarto.yml.\nWhen you are finished modifying your document and Project, push changes to Github using Github Desktop (see instructions here)."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/add-content.html#create-new-content",
    "href": "content/NMFS_OpenSciDirections/add-content.html#create-new-content",
    "title": "Customize Content",
    "section": "Create New Content",
    "text": "Create New Content\nAgain, assuming you have an RStudio project for your Github Repository, such as the example provided in the PAM Template Lab Manual: 1) Ensure that you have cloned the Github Repository using Github Desktop, and that you have created an RStudio project, following directions outlined here.\n\nOpen your RStudio project (here we will assume it is a clone of the PAM Template Lab Manual), and navigate to the ‘content’ folder (lower right hand side of RStudio, Files Tab). Select New Blank File, and in the drop-down, select Quarto Document. Then give your file a logical and descriptive name.\n\nUsing the Source editor, create a title header with the text you would like as your primary Header for this page (will appear as Header 1).\n\nAdd content below the header section, using either the Source or Visual editor in RStudio.\nAdd your new content to the _quarto.yml\nWhen you are finished modifying your document and Project, push changes to Github using Github Desktop (see instructions here)."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/add-content.html#examples",
    "href": "content/NMFS_OpenSciDirections/add-content.html#examples",
    "title": "Customize Content",
    "section": "Examples",
    "text": "Examples\nLooking at other people’s Quarto code is a great way to figure out how to do stuff. Most will have a link to a GitHub repo where you can see the raw code. Look for a link to edit page or see source code. This will usually be on the right. Or look for the GitHub icon somewhere.\n\nQuarto gallery\nnmfs-openscapes\nFaye lab manual\nquarto-titlepages Note the link to edit is broken. Go to repo and look in documentation directory."
  },
  {
    "objectID": "content/NMFS_OpenSciDirections/add-content.html#resources",
    "href": "content/NMFS_OpenSciDirections/add-content.html#resources",
    "title": "Customize Content",
    "section": "Resources",
    "text": "Resources\n\nQuarto documentation."
  },
  {
    "objectID": "content/FieldMethods.html",
    "href": "content/FieldMethods.html",
    "title": "Field Methods",
    "section": "",
    "text": "A field methods section is highly recommended to help your team keep track of all current and past fieldwork documentation. Things to include here can include hardware specifications, checklists for fieldwork prep, deployment and recovery methods, etc.\nYou can make this a section with subpages or link directly to a separate repository that includes more detailed methods.\nADRIFT example",
    "crumbs": [
      "Field Methods"
    ]
  },
  {
    "objectID": "content/SoftwareAnalysis.html",
    "href": "content/SoftwareAnalysis.html",
    "title": "Software & Analysis Methods",
    "section": "",
    "text": "A software and analysis methods section is required and should include subpages for both topics (analysis methods can be a subsection with pages for different anaylsis methods topics).",
    "crumbs": [
      "Software & Analysis Methods"
    ]
  },
  {
    "objectID": "content/SharedValues.html",
    "href": "content/SharedValues.html",
    "title": "Shared Values",
    "section": "",
    "text": "A shared values / lab culture page is optional but is highly recommended. Establishing these values as a team can help create a positive and inclusive environment, foster a shared vision, promote collaboration, and build team cohesion while supporting individual growth.\nSAEL example\nFaylab example",
    "crumbs": [
      "Optional Pages",
      "Shared Values"
    ]
  },
  {
    "objectID": "content/Offboarding.html",
    "href": "content/Offboarding.html",
    "title": "Offboarding",
    "section": "",
    "text": "This page is optional but can be extremely beneficial when a member of your team is transitioning out of their current position. Things to include here are directions for project documentation, data and code storage/sharing, turning in equipment, etc.\nFaylab example",
    "crumbs": [
      "Optional Pages",
      "Offboarding"
    ]
  }
]